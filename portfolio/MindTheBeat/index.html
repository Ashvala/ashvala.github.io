<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		
		<link rel="icon" href="/favicon.png" />		
		<style> 
		.bg-light{ 
			background-color: #fff;
		}
		</style>
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Mind the Beat (ICASSP 2021 Paper!)</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/aymanbagabas/iosevka-fonts@v6.1.2/dist/iosevka/iosevka.min.css" data-svelte="svelte-tobk0v"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" data-svelte="svelte-p6kbwv"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" data-svelte="svelte-p6kbwv"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" data-svelte="svelte-p6kbwv"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" data-svelte="svelte-p6kbwv">

		

		<link rel="modulepreload" href="/_app/start-97300be1.js">
		<link rel="modulepreload" href="/_app/chunks/vendor-f762ad99.js">
		<link rel="modulepreload" href="/_app/chunks/paths-28a87002.js">
		<link rel="modulepreload" href="/_app/layout.svelte-5172ddd0.js">
		<link rel="modulepreload" href="/_app/pages/portfolio/_portfolioslug_.svelte-bf392c96.js">
		<link rel="modulepreload" href="/_app/chunks/Nav-197b1bb9.js">
		<link rel="stylesheet" href="/_app/assets/start-61d1577b.css">
		<link rel="stylesheet" href="/_app/assets/vendor-28d9e71a.css">
		<link rel="stylesheet" href="/_app/assets/pages/portfolio/_portfolioslug_.svelte-471e4b4a.css">
		<link rel="stylesheet" href="/_app/assets/Nav-08d40821.css">

		<script type="module">
			import { start } from "/_app/start-97300be1.js";
			start({
				target: document.querySelector("#svelte"),
				paths: {"base":"","assets":""},
				session: {},
				host: location.host,
				route: true,
				spa: false,
				trailing_slash: "never",
				hydrate: {
					status: 200,
					error: null,
					nodes: [
						import("/_app/layout.svelte-5172ddd0.js"),
						import("/_app/pages/portfolio/_portfolioslug_.svelte-bf392c96.js")
					],
					page: {
						host: location.host, // TODO this is redundant
						path: "\u002Fportfolio\u002FMindTheBeat",
						query: new URLSearchParams(""),
						params: {portfolioslug:"MindTheBeat"}
					}
				}
			});
		</script>
	</head>
	<body>
		<div id="svelte">




<div class="container">

<div><nav class="svelte-1p3qrue"><h1><a href="/" class="svelte-1p3qrue">Ashvala Vinay </a></h1>
       <ul class="svelte-1p3qrue"><li class="svelte-1p3qrue"><a href="/blog" class="svelte-1p3qrue">Blog </a></li>
            <li class="svelte-1p3qrue"><a href="/portfolio" class="svelte-1p3qrue">Portfolio </a></li></ul></nav>
</div>
  <div class="row"><h1 class="title svelte-1yuhyb2">Mind the Beat (ICASSP 2021 Paper!)</h1>  
    <div class="portfolio_tech"><div class="portfolio_meta_tech_item svelte-1yuhyb2">Python
          </div><div class="portfolio_meta_tech_item svelte-1yuhyb2">Pytorch
          </div><div class="portfolio_meta_tech_item svelte-1yuhyb2">Madmom
          </div></div>  
    <div class="post_content svelte-1yuhyb2"><!-- HTML_TAG_START --><p><a href="https://ieeexplore.ieee.org/abstract/document/9414245">Published at ICASSP 2021!</a></p>
<p><em>From the paper</em>:</p>
<p><strong>Abstract:</strong>
We propose a deep learning approach to predicting audio event onsets in electroencephalogram (EEG) recorded from users as they listen to music. We use a publicly available dataset containing ten contemporary songs and concurrently recorded EEG. We generate a sequence of onset labels for the songs in our dataset and trained neural networks (a fully connected network (FCN) and a recurrent neural network (RNN)) to parse one second windows of input EEG to predict one second windows of onsets in the audio. We compare our RNN network to both the standard spectral-flux based novelty function and the FCN. We find that our RNN was able to produce results that reflected its ability to generalize better than the other methods.Since there are no pre-existing works on this topic, the numbers presented in this paper may serve as useful benchmarks for future approaches to this research problem.</p><!-- HTML_TAG_END --></div></div></div>



			<script type="application/json" data-type="svelte-data" data-url="/portfolio/MindTheBeat.json">{"status":200,"statusText":"","headers":{"content-type":"text/plain;charset=UTF-8"},"body":"{\"metadata\":{\"layout\":\"portfolio_page\",\"title\":\"Mind the Beat (ICASSP 2021 Paper!)\",\"Tech\":[\"Python\",\"Pytorch\",\"Madmom\"]},\"content\":\"\u003Cp\u003E\u003Ca href=\\\"https:\u002F\u002Fieeexplore.ieee.org\u002Fabstract\u002Fdocument\u002F9414245\\\"\u003EPublished at ICASSP 2021!\u003C\u002Fa\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cem\u003EFrom the paper\u003C\u002Fem\u003E:\u003C\u002Fp\u003E\\n\u003Cp\u003E\u003Cstrong\u003EAbstract:\u003C\u002Fstrong\u003E\\nWe propose a deep learning approach to predicting audio event onsets in electroencephalogram (EEG) recorded from users as they listen to music. We use a publicly available dataset containing ten contemporary songs and concurrently recorded EEG. We generate a sequence of onset labels for the songs in our dataset and trained neural networks (a fully connected network (FCN) and a recurrent neural network (RNN)) to parse one second windows of input EEG to predict one second windows of onsets in the audio. We compare our RNN network to both the standard spectral-flux based novelty function and the FCN. We find that our RNN was able to produce results that reflected its ability to generalize better than the other methods.Since there are no pre-existing works on this topic, the numbers presented in this paper may serve as useful benchmarks for future approaches to this research problem.\u003C\u002Fp\u003E\"}"}</script>
		</div>
	</body>
</html>
