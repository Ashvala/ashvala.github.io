<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />

    <link rel="icon" href="/favicon.png" />
    <style>
      .bg-light {
        background-color: #333;
      }
      .post_content img {
        max-width: 100%;
      }
      .post_content table{ 
        width: 100%;
      }
      .shadow-drop-center {
      -webkit-animation: shadow-drop-center 0.4s cubic-bezier(0.250, 0.460, 0.450, 0.940) both;
              animation: shadow-drop-center 0.4s cubic-bezier(0.250, 0.460, 0.450, 0.940) both;
    }
    @page { 
      margin-top: 10mm;
      size: letter;
    }

    @media print{
      p{
          font-size: 10pt;
          line-height: 1.25em;
          font-weight: 500;
      }
      .backButton{
          display: none !important;
      }
      .page{ 
          page-break-after: always;
          margin-top: 2px;
      }
      .svg_container{
          display: block !important; 
      }
    }
    @-webkit-keyframes shadow-drop-center {
      0% {
        -webkit-box-shadow: 0 0 0 0 rgba(0, 0, 0, 0);
                box-shadow: 0 0 0 0 rgba(0, 0, 0, 0);
      }
      100% {
        -webkit-box-shadow: 0 0 20px 0px rgba(0, 0, 0, 0.35);
                box-shadow: 0 0 20px 0px rgba(0, 0, 0, 0.35);
      }
    }
    @keyframes shadow-drop-center {
      0% {
        -webkit-box-shadow: 0 0 0 0 rgba(0, 0, 0, 0);
                box-shadow: 0 0 0 0 rgba(0, 0, 0, 0);
      }
      100% {
        -webkit-box-shadow: 0 0 20px 0px rgba(0, 0, 0, 0.35);
                box-shadow: 0 0 20px 0px rgba(0, 0, 0, 0.35);
      }
    }
      body{
        background: #efefef !important;
        color: white;
      }
    </style>

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link
      rel="stylesheet"
      href="https://maxst.icons8.com/vue-static/landings/line-awesome/line-awesome/1.3.0/css/line-awesome.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css"
    />
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css2?family=Merriweather">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lusitana">

    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">

    <title> Ashvala Vinay </title><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/aymanbagabas/iosevka-fonts@v6.1.2/dist/iosevka/iosevka.min.css" data-svelte="svelte-y6a7zc"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" data-svelte="svelte-p6kbwv"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" data-svelte="svelte-p6kbwv">

		

		<link rel="modulepreload" href="/_app/start-c4422fea.js">
		<link rel="modulepreload" href="/_app/chunks/index-047f7d26.js">
		<link rel="modulepreload" href="/_app/chunks/preload-helper-e4860ae8.js">
		<link rel="modulepreload" href="/_app/chunks/paths-28a87002.js">
		<link rel="modulepreload" href="/_app/layout.svelte-2b751067.js">
		<link rel="modulepreload" href="/_app/pages/index.svelte-bc124eb4.js">
		<link rel="modulepreload" href="/_app/chunks/Footer.svelte_svelte_type_style_lang-c8b8fb08.js">
		<link rel="modulepreload" href="/_app/chunks/Col-c1b93b68.js">
		<link rel="modulepreload" href="/_app/chunks/Row-962239be.js">
		<link rel="modulepreload" href="/_app/chunks/Nav-d2a73844.js">
		<link rel="modulepreload" href="/_app/chunks/Styles-e69be692.js">
		<link rel="stylesheet" href="/_app/assets/start-61d1577b.css">
		<link rel="stylesheet" href="/_app/assets/pages/index.svelte-c303dea6.css">
		<link rel="stylesheet" href="/_app/assets/Footer.svelte_svelte_type_style_lang-083ef82a.css">
		<link rel="stylesheet" href="/_app/assets/Row-bdc9687c.css">
		<link rel="stylesheet" href="/_app/assets/Nav-74014614.css">

		<script type="module">
			import { start } from "/_app/start-c4422fea.js";
			start({
				target: document.querySelector("#svelte"),
				paths: {"base":"","assets":""},
				session: {},
				host: location.host,
				route: true,
				spa: false,
				trailing_slash: "never",
				hydrate: {
					status: 200,
					error: null,
					nodes: [
						import("/_app/layout.svelte-2b751067.js"),
						import("/_app/pages/index.svelte-bc124eb4.js")
					],
					page: {
						host: location.host, // TODO this is redundant
						path: "\u002F",
						query: new URLSearchParams(""),
						params: {}
					}
				}
			});
		</script>
  </head>
  <body>
    <div id="svelte">






<div class="container"><div class="nav"><nav class="svelte-159vvmn"><h1 class="svelte-159vvmn"><a href="/" class="svelte-159vvmn">Ashvala Vinay </a></h1>
    <ul class="svelte-159vvmn"><li class="svelte-159vvmn"><a href="/blog" class="svelte-159vvmn">Blog </a></li>
      <li class="svelte-159vvmn"><a href="/cv" class="svelte-159vvmn">CV </a></li>
      <li class="svelte-159vvmn"><a href="/#publications" class="svelte-159vvmn">Publications </a></li></ul></nav>
</div>

  <div xs class="row"><div class="col"><img alt="Ashvala" src="/me.jpg" class="me_img img-thumbnail"></div>
    <div class="col"><div class="content svelte-1nqc45r"><h1 class="svelte-1nqc45r">Hi, I am Ashvala Vinay!</h1>
        <p class="svelte-1nqc45r">I am a PhD student at Georgia Tech&#39;s Center for Music Technology. I am
          currently working with Prof. Alexander Lerch on problems related to
          evaluating generative audio synthesizers.
        </p>
        <p class="svelte-1nqc45r">I graduated from Berklee College of Music in 2016. Following that, I
          worked on some personal projects and helped get two startups off the
          ground with their software engineering work. After that, I got my
          Masters in Music Technology at GTCMT.
        </p>
        <p class="svelte-1nqc45r">I play in a live coding band with my good buddy, <a href="https://ijc8.me">Ian Clester</a> called <a href="https://mergeconflict.live">Merge Conflict </a>.
        </p>
        <p class="svelte-1nqc45r">On this page, I will be sharing my work, and some posts where I will
          discuss music, technology and my progress through the course of my PhD
          work.
        </p>
        
        <div class="socials svelte-1nqc45r"><a href="https://github.com/ashvala" class="svelte-1nqc45r"><i class="lab la-github svelte-1nqc45r"></i>
              
            </a><a href="https://x.com/ashvala" class="svelte-1nqc45r"><i class="lab la-twitter svelte-1nqc45r"></i>
              
            </a><a href="https://instagram.com/ashvalav" class="svelte-1nqc45r"><i class="lab la-instagram svelte-1nqc45r"></i>
              
            </a><a href="https://scholar.google.com/citations?user=zsDPEzgAAAAJ&amp;hl=en&amp;oi=ao" class="svelte-1nqc45r">
                <svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="1em" height="1em" viewBox="0 0 50 50"><path d="M 25 2 C 12.309534 2 2 12.309534 2 25 C 2 37.690466 12.309534 48 25 48 C 37.690466 48 48 37.690466 48 25 C 48 12.309534 37.690466 2 25 2 z M 25 4 C 36.609534 4 46 13.390466 46 25 C 46 36.609534 36.609534 46 25 46 C 13.390466 46 4 36.609534 4 25 C 4 13.390466 13.390466 4 25 4 z M 21 11 L 11 20 L 17.78125 20 C 17.80125 22.847 19.967531 25.730469 23.769531 25.730469 C 24.129531 25.730469 24.529688 25.690391 24.929688 25.650391 C 24.749688 26.100391 24.560547 26.470078 24.560547 27.080078 C 24.560547 28.230078 25.140391 28.920078 25.650391 29.580078 C 24.020391 29.690078 20.989766 29.879531 18.759766 31.269531 C 16.629766 32.559531 15.980469 34.43 15.980469 35.75 C 15.980469 38.47 18.500469 41 23.730469 41 C 29.930469 41 33.220703 37.510547 33.220703 34.060547 C 33.220703 31.530547 31.779453 30.279922 30.189453 28.919922 L 28.900391 27.890625 C 28.500391 27.570625 27.949219 27.120312 27.949219 26.320312 C 27.949219 25.510313 28.500703 24.989766 28.970703 24.509766 C 30.480703 23.309766 32 21.960234 32 19.240234 C 32 18.197234 31.756203 17.348391 31.408203 16.650391 L 35 13.570312 L 35 17.277344 C 34.405 17.623344 34 18.261 34 19 L 34 25 C 34 26.104 34.896 27 36 27 C 37.104 27 38 26.104 38 25 L 38 19 C 38 18.262 37.595 17.624344 37 17.277344 L 37 12 C 37 11.957 36.980609 11.920906 36.974609 11.878906 L 38 11 L 21 11 z M 24.269531 14.240234 C 27.269531 14.240234 28.820312 18.35 28.820312 21 C 28.820312 21.65 28.739922 22.819922 27.919922 23.669922 C 27.339922 24.259922 26.370938 24.699219 25.460938 24.699219 C 22.370938 24.699219 20.949219 20.620156 20.949219 18.160156 C 20.949219 17.210156 21.14 16.220938 21.75 15.460938 C 22.33 14.710938 23.339531 14.240234 24.269531 14.240234 z M 26.039062 30.609375 C 26.409063 30.609375 26.590859 30.610391 26.880859 30.650391 C 29.620859 32.630391 30.800781 33.620234 30.800781 35.490234 C 30.800781 37.760234 28.97 39.460938 25.5 39.460938 C 21.64 39.460938 19.160156 37.590469 19.160156 34.980469 C 19.160156 32.370469 21.459766 31.499219 22.259766 31.199219 C 23.769766 30.679219 25.719062 30.609375 26.039062 30.609375 z"></path></svg>
              
            </a><a href="https://www.linkedin.com/in/ashvalavinay/" class="svelte-1nqc45r"><i class="lab la-linkedin svelte-1nqc45r"></i>
              
            </a></div></div></div></div>  
  
  <div class="row"></div>
  <hr> 
  <h3 id="pubs">Publications </h3>
  <div class="row"><div class="col"><div class="content svelte-1nqc45r"><div class="pdf_container svelte-1nqc45r"><div class="card_container svelte-1hig7tk"><div class="row"><div class="col"><div class="pdf_holder svelte-1hig7tk"><canvas class="pdf_viewer svelte-1hig7tk"></canvas>
            <div class="controls svelte-1hig7tk"><div class="left svelte-1hig7tk"><span class="svelte-1hig7tk">&lt;</span></div>
                <div class="middle svelte-1hig7tk"><span class="svelte-1hig7tk">1 / 0</span></div>
                <div class="right svelte-1hig7tk"><span class="svelte-1hig7tk">&gt;</span></div></div></div></div>
    <div class="col"><div class="meta_holder svelte-1hig7tk"><h3>AQUATk: An Audio Assessment Toolkit</h3>
            <p>Ashvala Vinay, Alexander Lerch</p>
            <p>ISMIR 2023, Late Breaking Demo</p>
            <p><span>Abstract: </span> Recent advancements in Neural Audio Synthesis (NAS) have outpaced the development of standardized evaluation methodologies and tools. To bridge this gap, we introduce AquaTk, an open-source Python library specifically designed to simplify and standardize the evaluation of NAS systems. AquaTk offers a range of audio quality metrics, including a unique Python implementation of the basic PEAQ algorithm, and operates in multiple modes to accommodate various user needs.</p>
            <div class="options svelte-1hig7tk"><div class="option svelte-1hig7tk"><span>Download </span></div>
                <div class="option svelte-1hig7tk"><span>BibTex </span></div></div></div></div></div>  
</div>
        </div><div class="pdf_container svelte-1nqc45r"><div class="card_container svelte-1hig7tk"><div class="row"><div class="col"><div class="pdf_holder svelte-1hig7tk"><canvas class="pdf_viewer svelte-1hig7tk"></canvas>
            <div class="controls svelte-1hig7tk"><div class="left svelte-1hig7tk"><span class="svelte-1hig7tk">&lt;</span></div>
                <div class="middle svelte-1hig7tk"><span class="svelte-1hig7tk">1 / 0</span></div>
                <div class="right svelte-1hig7tk"><span class="svelte-1hig7tk">&gt;</span></div></div></div></div>
    <div class="col"><div class="meta_holder svelte-1hig7tk"><h3>The Impact of Salient Musical Features in a Hybrid Recommendation System for a Sound Library</h3>
            <p>Jason Smith, Ashvala Vinay, Jason Freeman</p>
            <p>Joint Proceedings of the ACM IUI Workshops, 2023</p>
            <p><span>Abstract: </span> EarSketch is an online learning environment that teaches coding and music concepts through the computational manipulation of sounds selected from a large sound library. It features sound recommendations based on acoustic similarity and co-usage with a user&#39;s current sound selection in order to encourage exploration of the library. However, students have reported that the recommended sounds do not complement their current projects in terms of two areas: musical key and rhythm. We aim to improve the relevance of these recommendations through the inclusion of these two musically related features. This paper describes the addition of key signature and beat extraction to the EarSketch sound recommendation model in order to improve the musical compatibility of the recommendations with the sounds in a user’s project. Additionally, we present an analysis of the effects of these new recommendation strategies on user exploration and usage of the recommended sounds. The results of this analysis suggest that the addition of explicitly musically-relevant attributes increases the coverage of the sound library among sound recommendations as well as the sounds selected by users. It reflects the importance of including multiple musical attributes when building recommendation systems for creative and open-ended musical systems.</p>
            <div class="options svelte-1hig7tk"><div class="option svelte-1hig7tk"><span>Download </span></div>
                <div class="option svelte-1hig7tk"><span>BibTex </span></div></div></div></div></div>  
</div>
        </div><div class="pdf_container svelte-1nqc45r"><div class="card_container svelte-1hig7tk"><div class="row"><div class="col"><div class="pdf_holder svelte-1hig7tk"><canvas class="pdf_viewer svelte-1hig7tk"></canvas>
            <div class="controls svelte-1hig7tk"><div class="left svelte-1hig7tk"><span class="svelte-1hig7tk">&lt;</span></div>
                <div class="middle svelte-1hig7tk"><span class="svelte-1hig7tk">1 / 0</span></div>
                <div class="right svelte-1hig7tk"><span class="svelte-1hig7tk">&gt;</span></div></div></div></div>
    <div class="col"><div class="meta_holder svelte-1hig7tk"><h3>Evaluating Generative Audio Systems and Their Metrics</h3>
            <p>Ashvala Vinay, Alexander Lerch</p>
            <p>ISMIR 2022</p>
            <p><span>Abstract: </span> Recent years have seen considerable advances in audio synthesis with deep generative models. However, the state-of-the-art is very difficult to quantify; different studies often use different evaluation methodologies and different metrics when reporting results, making a direct comparison to other systems difficult if not impossible. Furthermore, the perceptual relevance and meaning of the reported metrics in most cases unknown, prohibiting any conclusive insights with respect to practical usability and audio quality. This paper presents a study that investigates state-of-the-art approaches side-by-side with (i) a set of previously proposed objective metrics for audio reconstruction, and with (ii) a listening study. The results indicate that currently used objective metrics are insufficient to describe the perceptual quality of current systems.</p>
            <div class="options svelte-1hig7tk"><div class="option svelte-1hig7tk"><span>Download </span></div>
                <div class="option svelte-1hig7tk"><span>BibTex </span></div></div></div></div></div>  
</div>
        </div><div class="pdf_container svelte-1nqc45r"><div class="card_container svelte-1hig7tk"><div class="row"><div class="col"><div class="pdf_holder svelte-1hig7tk"><canvas class="pdf_viewer svelte-1hig7tk"></canvas>
            <div class="controls svelte-1hig7tk"><div class="left svelte-1hig7tk"><span class="svelte-1hig7tk">&lt;</span></div>
                <div class="middle svelte-1hig7tk"><span class="svelte-1hig7tk">1 / 0</span></div>
                <div class="right svelte-1hig7tk"><span class="svelte-1hig7tk">&gt;</span></div></div></div></div>
    <div class="col"><div class="meta_holder svelte-1hig7tk"><h3>Mind the Beat: Detecting Audio Onsets from EEG Recordings of Music Listening</h3>
            <p>Ashvala Vinay, Alexander Lerch, Grace Leslie</p>
            <p>ICASSP 2021</p>
            <p><span>Abstract: </span> We propose a deep learning approach to predicting audio event onsets in electroencephalogram (EEG) recorded from users as they listen to music. We use a publicly available dataset containing ten contemporary songs and concurrently recorded EEG. We generate a sequence of onset labels for the songs in our dataset and trained neural networks (a fully connected network (FCN) and a recurrent neural network (RNN)) to parse one second windows of input EEG to predict one second windows of onsets in the audio. We compare our RNN network to both the standard spectral-flux based novelty function and the FCN. We find that our RNN was able to produce results that reflected its ability to generalize better than the other methods.Since there are no pre-existing works on this topic, the numbers presented in this paper may serve as useful benchmarks for future approaches to this research problem.</p>
            <div class="options svelte-1hig7tk"><div class="option svelte-1hig7tk"><span>Download </span></div>
                <div class="option svelte-1hig7tk"><span>BibTex </span></div></div></div></div></div>  
</div>
        </div></div></div></div></div>







			
		</div>
  </body>
</html>
